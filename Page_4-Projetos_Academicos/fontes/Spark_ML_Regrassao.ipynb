{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4989f62",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Big Data Real-Time Analytics com Python e Spark</font>\n",
    "\n",
    "## <font color='blue'>Mini-Projeto 5</font>\n",
    "\n",
    "### <font color='blue'>Machine Learning na Engenharia Civil com Apache Spark</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6508b5",
   "metadata": {},
   "source": [
    "![title](imagens/MP5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde12c1",
   "metadata": {},
   "source": [
    "O  Mini-Projeto 5  aborda  todo  o  processo  de  Machine  Learning  no  contexto  de  um problema na área de \n",
    "Engenharia Civil.\n",
    "\n",
    "Mas ao invés de aplicar as tarefas uma a uma, será criado módulos de automação. Ou seja, será desenvolvido um \n",
    "projeto próprio de sistema de AutoML, sem o uso de frameworks específicos e aplicando Machine Learning com o \n",
    "Spark MLlib no PySpark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62ea543",
   "metadata": {},
   "source": [
    "O concreto é o material mais importante na Engenharia Civil. \n",
    "\n",
    "A resistência à compressão do concreto é uma função altamente não linear da idade e dos ingredientes usados para \n",
    "prepararo concreto.\n",
    "\n",
    "Nosso trabalho será construir um modelo preditivo capaz de prever a força do concreto com  base  em  uma  série  de\n",
    "características  e  ingredientes  do  concreto.\n",
    "\n",
    "Usaremos  um  dataset disponível publicamente no link abaixo:\n",
    "    \n",
    "https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength\n",
    "    \n",
    "A variável “Concrete compressive strength”(coluna csMPano dataset) será a variável alvo e as demais serão as \n",
    "variáveis preditoras.\n",
    "\n",
    "Como  iremos  prever  um  valor  numérico  que  representa  a  força  do  concreto  e  temos dados  de  entrada  \n",
    "e  saída,  este  é  um  problema  de  regressão.  \n",
    "\n",
    "Vamos  experimentar  diferentes algoritmos  de  regressão  e  escolher  o que  apresentar  a melhor performance. \n",
    "\n",
    "Técnicas  de otimização de hiperparâmetros serão exploradas para chegar ao melhor modelo possível.\n",
    "\n",
    "Com o modelo treinado faremos previsões usando novos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a64757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.9.13\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "#!pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "#!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db12335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o findspark e inicializa\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99fa3cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import * # * importa tudo do pacote\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler#\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.regression import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9068f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b12a822",
   "metadata": {},
   "source": [
    "## Preparando o Ambiente Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ae9089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/28 14:22:39 WARN Utils: Your hostname, DataScience resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/04/28 14:22:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/28 14:22:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Criando o Spark Context\n",
    "sc = SparkContext(appName= 'Mini-Projeto5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc58e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setLogLevel(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78bbf6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a sessão\n",
    "spark  = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc5ab50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Mini-Projeto5</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f11a7adf5e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb17945",
   "metadata": {},
   "source": [
    "## Carregando o Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5ea1bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Carrega os dados\n",
    "dados = spark.read.csv('dados/dataset.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e35f425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8630db73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1030"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de registros\n",
    "dados.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f3a1c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+-----+----------------+---------------+-------------+---+-----+\n",
      "|cement| slag|flyash|water|superplasticizer|coarseaggregate|fineaggregate|age|csMPa|\n",
      "+------+-----+------+-----+----------------+---------------+-------------+---+-----+\n",
      "| 540.0|  0.0|   0.0|162.0|             2.5|         1040.0|        676.0| 28|79.99|\n",
      "| 540.0|  0.0|   0.0|162.0|             2.5|         1055.0|        676.0| 28|61.89|\n",
      "| 332.5|142.5|   0.0|228.0|             0.0|          932.0|        594.0|270|40.27|\n",
      "| 332.5|142.5|   0.0|228.0|             0.0|          932.0|        594.0|365|41.05|\n",
      "| 198.6|132.4|   0.0|192.0|             0.0|          978.4|        825.5|360| 44.3|\n",
      "| 266.0|114.0|   0.0|228.0|             0.0|          932.0|        670.0| 90|47.03|\n",
      "| 380.0| 95.0|   0.0|228.0|             0.0|          932.0|        594.0|365| 43.7|\n",
      "| 380.0| 95.0|   0.0|228.0|             0.0|          932.0|        594.0| 28|36.45|\n",
      "| 266.0|114.0|   0.0|228.0|             0.0|          932.0|        670.0| 28|45.85|\n",
      "| 475.0|  0.0|   0.0|228.0|             0.0|          932.0|        594.0| 28|39.29|\n",
      "+------+-----+------+-----+----------------+---------------+-------------+---+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualiza os dados no padrão do Spark DataFrame\n",
    "dados.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87a108ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>flyash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarseaggregate</th>\n",
       "      <th>fineaggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>csMPa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>47.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>43.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>36.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "      <td>45.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>39.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement   slag  flyash  water  superplasticizer  coarseaggregate  \\\n",
       "0   540.0    0.0     0.0  162.0               2.5           1040.0   \n",
       "1   540.0    0.0     0.0  162.0               2.5           1055.0   \n",
       "2   332.5  142.5     0.0  228.0               0.0            932.0   \n",
       "3   332.5  142.5     0.0  228.0               0.0            932.0   \n",
       "4   198.6  132.4     0.0  192.0               0.0            978.4   \n",
       "5   266.0  114.0     0.0  228.0               0.0            932.0   \n",
       "6   380.0   95.0     0.0  228.0               0.0            932.0   \n",
       "7   380.0   95.0     0.0  228.0               0.0            932.0   \n",
       "8   266.0  114.0     0.0  228.0               0.0            932.0   \n",
       "9   475.0    0.0     0.0  228.0               0.0            932.0   \n",
       "\n",
       "   fineaggregate  age  csMPa  \n",
       "0          676.0   28  79.99  \n",
       "1          676.0   28  61.89  \n",
       "2          594.0  270  40.27  \n",
       "3          594.0  365  41.05  \n",
       "4          825.5  360  44.30  \n",
       "5          670.0   90  47.03  \n",
       "6          594.0  365  43.70  \n",
       "7          594.0   28  36.45  \n",
       "8          670.0   28  45.85  \n",
       "9          594.0   28  39.29  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza os dados no formato do Pandas\n",
    "dados.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa26d616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cement: double (nullable = true)\n",
      " |-- slag: double (nullable = true)\n",
      " |-- flyash: double (nullable = true)\n",
      " |-- water: double (nullable = true)\n",
      " |-- superplasticizer: double (nullable = true)\n",
      " |-- coarseaggregate: double (nullable = true)\n",
      " |-- fineaggregate: double (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- csMPa: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Schema\n",
    "dados.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018bf2cf",
   "metadata": {},
   "source": [
    "## Módulo de Automação da Preparação de Dados\n",
    "\n",
    "O MLlib requer que todas as colunas de entrada do dataframe sejam vetorizadas. Vamos criar uma função Python que irá automatizar nosso trabalho de preparação dos dados, incluindo a vetorização e todas as tarefas necessárias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58deace5",
   "metadata": {},
   "source": [
    "Primeiro, vamos listar e remover valores ausentes (se existirem). Vamos focar neste projeto em Machine Learning, mas lembre-se sempre de checar valores ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdfc1614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas antes de remover valores ausentes: 1030\n",
      "Número de linhas após remover valores ausentes: 1030\n"
     ]
    }
   ],
   "source": [
    "# Separamos os dados ausentes (se existirem) e removemos (se existirem)\n",
    "dados_com_linhas_removidas = dados.na.drop()\n",
    "print('Número de linhas antes de remover valores ausentes:', dados.count())\n",
    "print('Número de linhas após remover valores ausentes:', dados_com_linhas_removidas.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93a3d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de preparação dos dados\n",
    "def func_modulo_prep_dados(df,\n",
    "                           variaveis_entrada,\n",
    "                           variaveis_saida,\n",
    "                           tratar_outliers = True,\n",
    "                           padronizar_dados = True):\n",
    "    \n",
    "    #Gerar um novo dataframe, renomeando o argumento que representa a variavél saida, por exigência do Spark\n",
    "    novo_df = df.withColumnRenamed(variavel_saida,'label')\n",
    "    \n",
    "    #Converte a variável alvo para o tipo numérico como float(Encondig)\n",
    "    if str(novo_df.schema['label'].dataType) != 'IntegerType':\n",
    "        novo_df = novo_df.withColumn('label', novo_df['label'].cast(FloatType()))\n",
    "    \n",
    "    \n",
    "    #Listas de Controle para as variáveis\n",
    "    variaveis_numericas =[]\n",
    "    variaveis_categoricas =[]\n",
    "    \n",
    "   # Se tiver variáveis de entrada do tipo String, converte para numérico\n",
    "    for coluna in variaveis_entrada:\n",
    "        \n",
    "        # Verifica se a variável é do tipo string\n",
    "        if str(novo_df.schema[coluna].dataType) == 'StringType':\n",
    "            \n",
    "            #Define a variável com um sufixo\n",
    "            novo_nome_coluna = coluna + '_num'\n",
    "            \n",
    "            # Adicionamos à lista de variáveis categóricas\n",
    "            variaveis_categoricas.append(novo_nome_coluna)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # Adiciona variávies numéricas na lista correspondente\n",
    "            variaveis_numericas.append(coluna)\n",
    "            \n",
    "            # Colocamos os dados no dataframe de variáveis indexadas\n",
    "            df_indexed = novo_df\n",
    "    \n",
    "    # Se o dataframe tiver dados do tipo String, aplicamos a indexação\n",
    "    # Verificamos se a lista de variávies categóricas não está vazia\n",
    "    if len(variaveis_categoricas) != 0:\n",
    "        \n",
    "        #loop pelas colunas\n",
    "        for coluna in novo_df:\n",
    "            \n",
    "            # Se a variável é do tipo String, é criada, treinada e aplicado indexador\n",
    "            if str(novo_df.schema[coluna].dataType) == 'StringType':\n",
    "                \n",
    "                # Cria o indexador\n",
    "                indexer = StringIndexer(inputCol= coluna, outputCol= coluna + '_num')\n",
    "                \n",
    "                # Treina e aplica o indexador\n",
    "                df_indexed = indexer.fit(novo_df).transform(novo_df)\n",
    "    else:\n",
    "        \n",
    "        # Se não tem variável categóricas, coloca os dados no dataframe de variáveis indexadas\n",
    "        df_indexed = novo_df\n",
    "        \n",
    "    # Tratamento de outliers\n",
    "    if tratar_outliers == True:\n",
    "        print('\\nAplicando o tratamento de outliers...')\n",
    "        \n",
    "        # Cria dicionário para Outliers\n",
    "        d = {}\n",
    "        \n",
    "        # Dicionário de quartis das variáveis do dataframe indexado(Para veriáveis numéricas)\n",
    "        for col in variaveis_numericas:\n",
    "            d[col] = df_indexed.approxQuantile(col,[0.01,0.99],0.25)\n",
    "        \n",
    "        # Agora aplicamos a transformação dependendo da distribuição de cada variável\n",
    "        for col in variaveis_numericas:\n",
    "            \n",
    "            # Extraimos a assimetria dos dados e usamos isso para tratar os outliers\n",
    "            skew = df_indexed.agg(skewness(df_indexed[col])).collect()\n",
    "            skew = skew[0][0]\n",
    "            \n",
    "            #Verificamos a assimetria e então aplicamos\n",
    "            \n",
    "            #trnasformação de log +1 se a assimetria for positiva\n",
    "            if skew > 1:\n",
    "                indexed = df_indexed.withColumn(col, log(when(df[col] < d[col][0], d[col][0])\\\n",
    "                .when(df_indexed[col] > d[col][1], d[col][1])\\\n",
    "                .otherwise(df_indexed[col] ) + 1).alias(col))\n",
    "                print(\"\\nA variável \" + col + \" foi tratada para assimetria positiva (direita) com skew =\", skew)\n",
    "            \n",
    "            # Transformação exponencial se a assimetria for negativa\n",
    "            elif skew < -1:\n",
    "                indexed = df_indexed.withColumn(col, \\\n",
    "                exp(when(df[col] < d[col][0], d[col][0])\\\n",
    "                .when(df_indexed[col] > d[col][1], d[col][1])\\\n",
    "                .otherwise(df_indexed[col] )).alias(col))\n",
    "                print(\"\\nA variável \" + col + \" foi tratada para assimetria negativa (esquerda) com skew =\", skew)\n",
    "    \n",
    "    # Vetorização\n",
    "    \n",
    "    # Lista final de atributos\n",
    "    lista_atributos = variaveis_numericas + variaveis_categoricas#Concatena as variávies\n",
    "    \n",
    "    # Cria o vetorizador para os atributos\n",
    "    vetorizador = VectorAssembler(inputCols = lista_atributos, outputCol = 'features')\n",
    "    \n",
    "    # Aplica o vetorizadoe ao conjunto de dados\n",
    "    dados_vetorizados = vetorizador.transform(df_indexed).select('features','label')\n",
    "    \n",
    "    # Se a flag padronizar_dados está como True, então padronizamos os dados colocando-os na mesma escala\n",
    "    if padronizar_dados == True:\n",
    "        print(\"\\nPadronizando o conjunto de dados para o intervalo de 0 a 1...\")\n",
    "        \n",
    "        # Cria o scaler\n",
    "        scaler = MinMaxScaler(inputCol= 'features', outputCol= 'scaledFeatures')\n",
    "        \n",
    "        # Calcula o sumário de estatísticas e gera o padronizador\n",
    "        global scalerModel\n",
    "        scalerModel = scaler.fit(dados_vetorizados)\n",
    "        \n",
    "        #Padroniza as variáveis para o intervalo[min,max]\n",
    "        dados_padronizados = scalerModel.transform(dados_vetorizados)\n",
    "        \n",
    "        # Gera os dados finais\n",
    "        dados_finais = dados_padronizados.select('label','scaledFeatures')\n",
    "        \n",
    "        #Renomeia as colunas(requerido pelo Spark)\n",
    "        dados_finais = dados_finais.withColumnRenamed('scaledFeatures','features')\n",
    "        \n",
    "        print(\"\\nPadronização Concluída!\")\n",
    "\n",
    "   # Se a flag está como False, então não padronizamos os dados\n",
    "    else:\n",
    "        print(\"\\nOs dados não serão padronizados pois a flag padronizar_dados está com o valor False.\")\n",
    "        dados_finais = dados_vetorizados\n",
    "    \n",
    "    return dados_finais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb615ed",
   "metadata": {},
   "source": [
    "> Agora aplicamos o módulo de preparação dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e7896d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variáveis de entrada(todas menos a target)\n",
    "variaveis_entrada = dados.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64a6dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável Alvo\n",
    "variavel_saida = dados.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cadc36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aplicando o tratamento de outliers...\n",
      "\n",
      "A variável age foi tratada para assimetria positiva (direita) com skew = 3.2644145354168086\n",
      "\n",
      "Padronizando o conjunto de dados para o intervalo de 0 a 1...\n",
      "\n",
      "Padronização Concluída!\n"
     ]
    }
   ],
   "source": [
    "# Aplica a função\n",
    "dados_finais = func_modulo_prep_dados(dados, variaveis_entrada, variavel_saida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b5bf60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|features                                                                                                                      |\n",
      "+-----+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|79.99|[1.0,0.0,0.0,0.3210862619808307,0.07763975155279502,0.6947674418604651,0.20572002007024587,0.07417582417582418]               |\n",
      "|61.89|[1.0,0.0,0.0,0.3210862619808307,0.07763975155279502,0.7383720930232558,0.20572002007024587,0.07417582417582418]               |\n",
      "|40.27|[0.526255707762557,0.3964941569282137,0.0,0.8482428115015974,0.0,0.3808139534883721,0.0,0.739010989010989]                    |\n",
      "|41.05|[0.526255707762557,0.3964941569282137,0.0,0.8482428115015974,0.0,0.3808139534883721,0.0,1.0]                                  |\n",
      "|44.3 |[0.22054794520547943,0.3683917640511965,0.0,0.560702875399361,0.0,0.5156976744186046,0.58078273958856,0.9862637362637363]     |\n",
      "|47.03|[0.3744292237442922,0.31719532554257096,0.0,0.8482428115015974,0.0,0.3808139534883721,0.19066733567486202,0.24450549450549453]|\n",
      "|43.7 |[0.634703196347032,0.2643294379521425,0.0,0.8482428115015974,0.0,0.3808139534883721,0.0,1.0]                                  |\n",
      "|36.45|[0.634703196347032,0.2643294379521425,0.0,0.8482428115015974,0.0,0.3808139534883721,0.0,0.07417582417582418]                  |\n",
      "|45.85|[0.3744292237442922,0.31719532554257096,0.0,0.8482428115015974,0.0,0.3808139534883721,0.19066733567486202,0.07417582417582418]|\n",
      "|39.29|(8,[0,3,5,7],[0.8515981735159817,0.8482428115015974,0.3808139534883721,0.07417582417582418])                                  |\n",
      "+-----+------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualiza\n",
    "dados_finais.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9d6c7a",
   "metadata": {},
   "source": [
    "## Verificando a Correlação\n",
    "\n",
    "Vamos nos certificar de que não temos multicolinearidade antes de prosseguirmos. Lembre-se das seguintes diretrizes para o Coeficiente de Correlação de Pearson:\n",
    "\n",
    "- .00-.19 (correlação muito fraca)\n",
    "- .20-.39 (correlação fraca)\n",
    "- .40-.59 (correlação moderada)\n",
    "- .60-.79 (correlação forte)\n",
    "- .80-1.0 (correlação muito forte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5df0b1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 52:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Extrai a correlação\n",
    "coeficientes_corr = Correlation.corr(dados_finais, 'features','pearson').collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89d3f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte o resultado em array\n",
    "array_corr = coeficientes_corr.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7e74ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.27521591, -0.39746734, -0.08158675,  0.09238617,\n",
       "        -0.10934899, -0.22271785,  0.08194602],\n",
       "       [-0.27521591,  1.        , -0.3235799 ,  0.10725203,  0.04327042,\n",
       "        -0.28399861, -0.28160267, -0.04424602],\n",
       "       [-0.39746734, -0.3235799 ,  1.        , -0.25698402,  0.37750315,\n",
       "        -0.00996083,  0.07910849, -0.15437052],\n",
       "       [-0.08158675,  0.10725203, -0.25698402,  1.        , -0.65753291,\n",
       "        -0.1822936 , -0.45066117,  0.27761822],\n",
       "       [ 0.09238617,  0.04327042,  0.37750315, -0.65753291,  1.        ,\n",
       "        -0.26599915,  0.22269123, -0.19270003],\n",
       "       [-0.10934899, -0.28399861, -0.00996083, -0.1822936 , -0.26599915,\n",
       "         1.        , -0.17848096, -0.00301588],\n",
       "       [-0.22271785, -0.28160267,  0.07910849, -0.45066117,  0.22269123,\n",
       "        -0.17848096,  1.        , -0.1560947 ],\n",
       "       [ 0.08194602, -0.04424602, -0.15437052,  0.27761822, -0.19270003,\n",
       "        -0.00301588, -0.1560947 ,  1.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a051a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08194602387182176\n",
      "-0.044246019304454175\n",
      "-0.15437051606792915\n",
      "0.27761822152100296\n",
      "-0.19270002804347258\n",
      "-0.0030158803467436645\n",
      "-0.15609470264758615\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Lista a correlação entre os atributos e a variável alvo\n",
    "for item in array_corr:\n",
    "    print(item[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd040f6",
   "metadata": {},
   "source": [
    "## Divisão em Dados de Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4954a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão com proporção 70/30\n",
    "dados_treino, dados_teste = dados_finais.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2ac650",
   "metadata": {},
   "source": [
    "## Módulo de AutoML (Automated Machine Learning)\n",
    "\n",
    "https://spark.apache.org/docs/latest/ml-classification-regression.html#regression\n",
    "\n",
    "Vamos criar uma função para automatizar o uso de diversos algoritmos. Nossa função irá criar, treinar e avaliar cada um deles com diferentes combinações de hiperparâmetros. E então escolheremos o modelo de melhor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af07930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulo de Machine Learning\n",
    "def func_modulo_ml(algoritmo_regressao):\n",
    "\n",
    "    # Função para obter o tipo do algoritmo de regressão e criar a instância do objeto\n",
    "    # Usaremos isso para automatizar nosso processo\n",
    "    def func_tipo_algo(algo_regressao):\n",
    "        algoritmo = algo_regressao\n",
    "        tipo_algo = type(algoritmo).__name__\n",
    "        return tipo_algo\n",
    "    \n",
    "    # Aplica a função anterior\n",
    "    tipo_algo = func_tipo_algo(algoritmo_regressao)\n",
    "\n",
    "    # Se o algoritmo for Regressão Linear, entramos neste bloco if\n",
    "    if tipo_algo == \"LinearRegression\":\n",
    "        \n",
    "        # Treinamos a primeira versão do modelo sem validação cruzada\n",
    "        modelo = regressor.fit(dados_treino)\n",
    "        \n",
    "        # Métricas do modelo\n",
    "        print('\\033[1m' + \"Modelo de Regressão Linear Sem Validação Cruzada:\" + '\\033[0m')\n",
    "        print(\"\")\n",
    "        \n",
    "        # Avalia o modelo com dados de teste\n",
    "        resultado_teste = modelo.evaluate(dados_teste)\n",
    "\n",
    "        # Imprime as métricas de erro do modelo com dados de teste\n",
    "        print(\"RMSE em Teste: {}\".format(resultado_teste.rootMeanSquaredError))\n",
    "        print(\"Coeficiente R2 em Teste: {}\".format(resultado_teste.r2))\n",
    "        print(\"\")\n",
    "        \n",
    "        # Agora vamos criar a segunda versão do modelo com mesmo algoritmo, mas usando validação cruzada\n",
    "        \n",
    "        # Prepara o grid de hiperparâmetros\n",
    "        paramGrid = (ParamGridBuilder().addGrid(regressor.regParam, [0.1, 0.01]).build())\n",
    "        \n",
    "        # Cria os avaliadores\n",
    "        eval_rmse = RegressionEvaluator(metricName = \"rmse\")\n",
    "        eval_r2 = RegressionEvaluator(metricName = \"r2\")\n",
    "        \n",
    "        # Cria o Cross Validator\n",
    "        crossval = CrossValidator(estimator = regressor,\n",
    "                                  estimatorParamMaps = paramGrid,\n",
    "                                  evaluator = eval_rmse,\n",
    "                                  numFolds = 3) \n",
    "        \n",
    "        print('\\033[1m' + \"Modelo de Regressão Linear Com Validação Cruzada:\" + '\\033[0m')\n",
    "        print(\"\")\n",
    "        \n",
    "        # Treina o modelo com validação cruzada\n",
    "        modelo = crossval.fit(dados_treino)\n",
    "        \n",
    "        # Salva o melhor modelo da versão 2\n",
    "        global LR_BestModel \n",
    "        LR_BestModel = modelo.bestModel\n",
    "                \n",
    "        # Previsões com dados de teste\n",
    "        previsoes = LR_BestModel.transform(dados_teste)\n",
    "        \n",
    "        # Avaliação do melhor modelo\n",
    "        resultado_teste_rmse = eval_rmse.evaluate(previsoes)\n",
    "        print('RMSE em Teste:', resultado_teste_rmse)\n",
    "        \n",
    "        resultado_teste_r2 = eval_r2.evaluate(previsoes)\n",
    "        print('Coeficiente R2 em Teste:', resultado_teste_r2)\n",
    "        print(\"\")\n",
    "    \n",
    "        # Lista de colunas para colocar no dataframe de resumo\n",
    "        columns = ['Regressor', 'Resultado_RMSE', 'Resultado_R2']\n",
    "        \n",
    "        # Formata os resultados e cria o dataframe\n",
    "        \n",
    "        # Formata as métricas e nome do algoritmo\n",
    "        rmse_str = [str(resultado_teste_rmse)] \n",
    "        r2_str = [str(resultado_teste_r2)] \n",
    "        tipo_algo = [tipo_algo] \n",
    "        \n",
    "        # Cria o dataframne\n",
    "        df_resultado = spark.createDataFrame(zip(tipo_algo, rmse_str, r2_str), schema = columns)\n",
    "        \n",
    "        # Grava os resultados no dataframe\n",
    "        df_resultado = df_resultado.withColumn('Resultado_RMSE', df_resultado.Resultado_RMSE.substr(0, 5))\n",
    "        df_resultado = df_resultado.withColumn('Resultado_R2', df_resultado.Resultado_R2.substr(0, 5))\n",
    "        \n",
    "        return df_resultado\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # Verificamos se o algoritmo é o Decision Tree e criamos o grid de hiperparâmetros\n",
    "        if tipo_algo in(\"DecisionTreeRegressor\"):\n",
    "            paramGrid = (ParamGridBuilder().addGrid(regressor.maxBins, [10, 20, 40]).build())\n",
    "\n",
    "        # Verificamos se o algoritmo é o Random Forest e criamos o grid de hiperparâmetros\n",
    "        if tipo_algo in(\"RandomForestRegressor\"):\n",
    "            paramGrid = (ParamGridBuilder().addGrid(regressor.numTrees, [5, 20]).build())\n",
    "\n",
    "        # Verificamos se o algoritmo é o GBT e criamos o grid de hiperparâmetros\n",
    "        if tipo_algo in(\"GBTRegressor\"):\n",
    "            paramGrid = (ParamGridBuilder() \\\n",
    "                         .addGrid(regressor.maxBins, [10, 20]) \\\n",
    "                         .addGrid(regressor.maxIter, [10, 15])\n",
    "                         .build())\n",
    "            \n",
    "        # Verificamos se o algoritmo é o Isotonic \n",
    "        if tipo_algo in(\"IsotonicRegression\"):\n",
    "            paramGrid = (ParamGridBuilder().addGrid(regressor.isotonic, [True, False]).build())\n",
    "\n",
    "        # Cria os avaliadores\n",
    "        eval_rmse = RegressionEvaluator(metricName = \"rmse\")\n",
    "        eval_r2 = RegressionEvaluator(metricName = \"r2\")\n",
    "        \n",
    "        # Prepara o Cross Validator\n",
    "        crossval = CrossValidator(estimator = regressor,\n",
    "                                  estimatorParamMaps = paramGrid,\n",
    "                                  evaluator = eval_rmse,\n",
    "                                  numFolds = 3) \n",
    "        \n",
    "        # Treina o modelo usando validação cruzada\n",
    "        modelo = crossval.fit(dados_treino)\n",
    "        \n",
    "        # Extrai o melhor modelo\n",
    "        BestModel = modelo.bestModel\n",
    "\n",
    "        # Resumo de cada modelo\n",
    "        \n",
    "        # Métricas do modelo\n",
    "        if tipo_algo in(\"DecisionTreeRegressor\"):\n",
    "            \n",
    "            # Variável global\n",
    "            global DT_BestModel \n",
    "            DT_BestModel = modelo.bestModel\n",
    "            \n",
    "            # Previsões com dados de teste\n",
    "            previsoes_DT = DT_BestModel.transform(dados_teste)\n",
    "            \n",
    "            print('\\033[1m' + \"Modelo Decision Tree Com Validação Cruzada:\" + '\\033[0m')\n",
    "            print(\" \")\n",
    "            \n",
    "            # Avaliação do modelo\n",
    "            resultado_teste_rmse = eval_rmse.evaluate(previsoes_DT)\n",
    "            print('RMSE em Teste:', resultado_teste_rmse)\n",
    "        \n",
    "            resultado_teste_r2 = eval_r2.evaluate(previsoes_DT)\n",
    "            print('Coeficiente R2 em Teste:', resultado_teste_r2)\n",
    "            print(\"\")\n",
    "        \n",
    "        # Métricas do modelo\n",
    "        if tipo_algo in(\"RandomForestRegressor\"):\n",
    "            \n",
    "            # Variável global\n",
    "            global RF_BestModel \n",
    "            RF_BestModel = modelo.bestModel\n",
    "            \n",
    "            # Previsões com dados de teste\n",
    "            previsoes_RF = RF_BestModel.transform(dados_teste)\n",
    "            \n",
    "            print('\\033[1m' + \"Modelo RandomForest Com Validação Cruzada:\" + '\\033[0m')\n",
    "            print(\" \")\n",
    "            \n",
    "            # Avaliação do modelo\n",
    "            resultado_teste_rmse = eval_rmse.evaluate(previsoes_RF)\n",
    "            print('RMSE em Teste:', resultado_teste_rmse)\n",
    "        \n",
    "            resultado_teste_r2 = eval_r2.evaluate(previsoes_RF)\n",
    "            print('Coeficiente R2 em Teste:', resultado_teste_r2)\n",
    "            print(\"\")\n",
    "        \n",
    "        # Métricas do modelo\n",
    "        if tipo_algo in(\"GBTRegressor\"):\n",
    "\n",
    "            # Variável global\n",
    "            global GBT_BestModel \n",
    "            GBT_BestModel = modelo.bestModel\n",
    "            \n",
    "            # Previsões com dados de teste\n",
    "            previsoes_GBT = GBT_BestModel.transform(dados_teste)\n",
    "            \n",
    "            print('\\033[1m' + \"Modelo Gradient-Boosted Tree (GBT) Com Validação Cruzada:\" + '\\033[0m')\n",
    "            print(\" \")\n",
    "            \n",
    "            # Avaliação do modelo\n",
    "            resultado_teste_rmse = eval_rmse.evaluate(previsoes_GBT)\n",
    "            print('RMSE em Teste:', resultado_teste_rmse)\n",
    "        \n",
    "            resultado_teste_r2 = eval_r2.evaluate(previsoes_GBT)\n",
    "            print('Coeficiente R2 em Teste:', resultado_teste_r2)\n",
    "            print(\"\")\n",
    "            \n",
    "        # Métricas do modelo\n",
    "        if tipo_algo in(\"IsotonicRegression\"):\n",
    "\n",
    "            # Variável global\n",
    "            global ISO_BestModel \n",
    "            ISO_BestModel = modelo.bestModel\n",
    "            \n",
    "            # Previsões com dados de teste\n",
    "            previsoes_ISO = ISO_BestModel.transform(dados_teste)\n",
    "            \n",
    "            print('\\033[1m' + \"Modelo Isotonic Com Validação Cruzada:\" + '\\033[0m')\n",
    "            print(\" \")\n",
    "            \n",
    "            # Avaliação do modelo\n",
    "            resultado_teste_rmse = eval_rmse.evaluate(previsoes_ISO)\n",
    "            print('RMSE em Teste:', resultado_teste_rmse)\n",
    "        \n",
    "            resultado_teste_r2 = eval_r2.evaluate(previsoes_ISO)\n",
    "            print('Coeficiente R2 em Teste:', resultado_teste_r2)\n",
    "            print(\"\")\n",
    "                    \n",
    "        # Lista de colunas para colocar no dataframe de resumo\n",
    "        columns = ['Regressor', 'Resultado_RMSE', 'Resultado_R2']\n",
    "        \n",
    "        # Faz previsões com dados de teste\n",
    "        previsoes = modelo.transform(dados_teste)\n",
    "        \n",
    "        # Avalia o modelo para gravar o resultado\n",
    "        eval_rmse = RegressionEvaluator(metricName = \"rmse\")\n",
    "        rmse = eval_rmse.evaluate(previsoes)\n",
    "        rmse_str = [str(rmse)]\n",
    "        \n",
    "        eval_r2 = RegressionEvaluator(metricName = \"r2\")\n",
    "        r2 = eval_r2.evaluate(previsoes)\n",
    "        r2_str = [str(r2)]\n",
    "         \n",
    "        tipo_algo = [tipo_algo] \n",
    "        \n",
    "        # Cria o dataframe\n",
    "        df_resultado = spark.createDataFrame(zip(tipo_algo, rmse_str, r2_str), schema = columns)\n",
    "        \n",
    "        # Grava o resultado no dataframe\n",
    "        df_resultado = df_resultado.withColumn('Resultado_RMSE', df_resultado.Resultado_RMSE.substr(0, 5))\n",
    "        df_resultado = df_resultado.withColumn('Resultado_R2', df_resultado.Resultado_R2.substr(0, 5))\n",
    "        \n",
    "        return df_resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0f95be",
   "metadata": {},
   "source": [
    "> Agora executamos o módulo de Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1126fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de algoritmos\n",
    "regressores = [LinearRegression(),\n",
    "               DecisionTreeRegressor(),\n",
    "               RandomForestRegressor(),\n",
    "               GBTRegressor(),\n",
    "               IsotonicRegression()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e961ca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de colunas e valores\n",
    "colunas = ['Regressor', 'Resultado_RMSE', 'Resultado_R2']\n",
    "valores = [(\"N/A\", \"N/A\", \"N/A\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "813a395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara a tabela de resumo\n",
    "df_resultados_treinamento = spark.createDataFrame(valores, colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1d0fd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModelo de Regressão Linear Sem Validação Cruzada:\u001b[0m\n",
      "\n",
      "RMSE em Teste: 10.638716332789414\n",
      "Coeficiente R2 em Teste: 0.5996076456770542\n",
      "\n",
      "\u001b[1mModelo de Regressão Linear Com Validação Cruzada:\u001b[0m\n",
      "\n",
      "RMSE em Teste: 10.642212240017546\n",
      "Coeficiente R2 em Teste: 0.5993444627027547\n",
      "\n",
      "\u001b[1mModelo Decision Tree Com Validação Cruzada:\u001b[0m\n",
      " \n",
      "RMSE em Teste: 8.519208550017536\n",
      "Coeficiente R2 em Teste: 0.7432527401284419\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/home/evandro/anaconda3/lib/python3.9/site-packages/pyspark/jars/spark-core_2.12-3.3.1.jar) to field java.nio.charset.Charset.name\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModelo RandomForest Com Validação Cruzada:\u001b[0m\n",
      " \n",
      "RMSE em Teste: 7.54231110538922\n",
      "Coeficiente R2 em Teste: 0.7987591226907497\n",
      "\n",
      "\u001b[1mModelo Gradient-Boosted Tree (GBT) Com Validação Cruzada:\u001b[0m\n",
      " \n",
      "RMSE em Teste: 6.554795407372699\n",
      "Coeficiente R2 em Teste: 0.8480062958690837\n",
      "\n",
      "\u001b[1mModelo Isotonic Com Validação Cruzada:\u001b[0m\n",
      " \n",
      "RMSE em Teste: 14.146547862028632\n",
      "Coeficiente R2 em Teste: 0.29204074424230897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop de treinamento\n",
    "for regressor in regressores:\n",
    "    \n",
    "    # Para cada regressor obtém o resultado\n",
    "    resultado_modelo = func_modulo_ml(regressor)\n",
    "    \n",
    "    # Grava os resultados\n",
    "    df_resultados_treinamento = df_resultados_treinamento.union(resultado_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b27f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna as linhas diferentes de N/A\n",
    "df_resultados_treinamento = df_resultados_treinamento.where(\"Regressor!='N/A'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "619a47cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------+------------+\n",
      "|Regressor            |Resultado_RMSE|Resultado_R2|\n",
      "+---------------------+--------------+------------+\n",
      "|LinearRegression     |10.64         |0.599       |\n",
      "|DecisionTreeRegressor|8.519         |0.743       |\n",
      "|RandomForestRegressor|7.542         |0.798       |\n",
      "|GBTRegressor         |6.554         |0.848       |\n",
      "|IsotonicRegression   |14.14         |0.292       |\n",
      "+---------------------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprime\n",
    "df_resultados_treinamento.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b969d72",
   "metadata": {},
   "source": [
    " > O modelo GBT apresentou a melhor performance geral e será usado em produção."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219db6b4",
   "metadata": {},
   "source": [
    "## Fazendo Previsões com o Modelo Treinado\n",
    "\n",
    "Para fazer as previsões com o modelo treinado, vamos preparar um registro com novos dados.\n",
    "\n",
    "- Cement: 540\n",
    "- Blast Furnace Slag: 0\n",
    "- Fly Ash: 0\n",
    "- Water: 162\n",
    "- Superplasticizer: 2.5\n",
    "- Coarse Aggregate: 1040\n",
    "- Fine Aggregate: 676\n",
    "- Age: 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2d48129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista dos valores de entrada\n",
    "values = [(540,0.0,0.0,162,2.5,1040,676,28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06aef0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomes das colunas\n",
    "column_names = dados.columns\n",
    "column_names = column_names[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f07ce92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associa valores aos nomes de coluna\n",
    "novos_dados = spark.createDataFrame(values, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac7fd862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos na coluna age a mesma transformação aplicada na preparação dos dados.\n",
    "novos_dados = novos_dados.withColumn(\"age\", log(\"age\") +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1fa7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de atributos\n",
    "lista_atributos = [\"cement\",\n",
    "                   \"slag\",\n",
    "                   \"flyash\",\n",
    "                   \"water\",\n",
    "                   \"superplasticizer\",\n",
    "                   \"coarseaggregate\",\n",
    "                   \"fineaggregate\",\n",
    "                   \"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eec70cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o vetorizador\n",
    "assembler = VectorAssembler(inputCols = lista_atributos, outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5910d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma os dados em vetor\n",
    "novos_dados = assembler.transform(novos_dados).select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92092014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padroniza os dados (mesma transformação aplicada aos dados de treino)\n",
    "novos_dados_scaled = scalerModel.transform(novos_dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3f528a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona a coluna resultante\n",
    "novos_dados_final = novos_dados_scaled.select('scaledFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f257571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeia a coluna (requerimento do MLlib)\n",
    "novos_dados_final = novos_dados_final.withColumnRenamed('scaledFeatures','features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef6fd120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com novos dados usando o modelo de melhor performance\n",
    "previsoes_novos_dados = GBT_BestModel.transform(novos_dados_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e1fb00f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|            features|       prediction|\n",
      "+--------------------+-----------------+\n",
      "|[1.0,0.0,0.0,0.32...|46.02643612888154|\n",
      "+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resultado\n",
    "previsoes_novos_dados.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ea2ead",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
